# C√°ch s·ª≠ d·ª•ng AI Discussion MCP Server trong Augment

## üéØ M·ª•c ti√™u

B·∫°n c√≥ th·ªÉ g√µ trong Augment:
> "H√£y th·∫£o lu·∫≠n v·ªÅ v·∫•n ƒë·ªÅ n√†y gi·ªØa r1 v√† gemini flash"

V√† Augment s·∫Ω t·ª± ƒë·ªông:
1. G·ªçi tool `discuss` t·ª´ MCP server
2. Th·∫£o lu·∫≠n gi·ªØa Claude Sonnet (b·∫°n), DeepSeek R1, v√† Gemini Flash
3. T·ªïng h·ª£p k·∫øt qu·∫£ v√† ƒë∆∞a ra synthesis

## üöÄ Setup

### B∆∞·ªõc 1: Copy MCP Server

Copy th∆∞ m·ª•c `mcp_sdk` v√†o m·ªôt v·ªã tr√≠ c·ªë ƒë·ªãnh tr√™n m√°y:
```bash
cp -r /Users/linhmh/Projects/zen-mcp-server/mcp_sdk ~/ai-discussion-server/
```

### B∆∞·ªõc 2: Configure Augment

Th√™m v√†o Augment config (th∆∞·ªùng l√† `~/.config/augment/config.json` ho·∫∑c t∆∞∆°ng t·ª±):

```json
{
  "mcpServers": {
    "ai-discussion": {
      "command": "python3",
      "args": ["mcp_discussion_server.py"],
      "cwd": "/Users/linhmh/ai-discussion-server/mcp_sdk",
      "env": {
        "OPENROUTER_API_KEY": "your_openrouter_api_key_here",
        "GEMINI_API_KEY": "your_gemini_api_key_here"
      }
    }
  }
}
```

**L∆∞u √Ω:** Thay ƒë·ªïi `cwd` path cho ph√π h·ª£p v·ªõi v·ªã tr√≠ b·∫°n copy server.

### B∆∞·ªõc 3: Restart Augment

Restart Augment ƒë·ªÉ load MCP server m·ªõi.

## üõ†Ô∏è Available Tools

### 1. `discuss` - Multi-Model Discussion

**M√¥ t·∫£:** T·∫°o cu·ªôc th·∫£o lu·∫≠n gi·ªØa nhi·ªÅu AI models v·ªÅ m·ªôt topic

**Usage trong Augment:**
```
H√£y th·∫£o lu·∫≠n v·ªÅ "Should I use React or Vue for my startup?" gi·ªØa r1 v√† gemini flash
```

**Parameters:**
- `topic` (required): Ch·ªß ƒë·ªÅ th·∫£o lu·∫≠n
- `models` (optional): List models ƒë·ªÉ tham gia
- `include_claude` (optional): C√≥ bao g·ªìm Claude perspective kh√¥ng

**Example output:**
```
üó£Ô∏è Multi-Model Discussion: Should I use React or Vue for my startup?
============================================================

ü§ñ Claude Sonnet (Augment Assistant):
As your Augment assistant, here's my perspective on: Should I use React or Vue for my startup?
[Claude's analysis...]

ü§ñ Model 1: deepseek/deepseek-r1
[DeepSeek R1's analysis...]

ü§ñ Model 2: google/gemini-flash-1.5  
[Gemini's analysis...]

üéØ Synthesis & Conclusion
[Combined analysis from all models...]
```

### 2. `chat` - Simple Chat

**M√¥ t·∫£:** Chat ƒë∆°n gi·∫£n v·ªõi m·ªôt model c·ª• th·ªÉ

**Usage:**
```
Chat v·ªõi deepseek r1: "Explain async/await in Python"
```

### 3. `consensus` - Multi-Model Consensus

**M√¥ t·∫£:** L·∫•y consensus t·ª´ nhi·ªÅu models

**Usage:**
```
L·∫•y consensus v·ªÅ "Best database for a social media app"
```

## üé® Usage Examples trong Augment

### Example 1: Architecture Discussion
```
User: H√£y th·∫£o lu·∫≠n v·ªÅ microservices vs monolith cho startup gi·ªØa r1 v√† gemini

Augment s·∫Ω call: discuss(topic="microservices vs monolith cho startup", models=["deepseek/deepseek-r1", "google/gemini-flash-1.5"])
```

### Example 2: Technology Choice
```
User: So s√°nh Python vs Go cho backend API, c·∫ßn √Ω ki·∫øn t·ª´ nhi·ªÅu AI

Augment s·∫Ω call: discuss(topic="Python vs Go cho backend API")
```

### Example 3: Code Review Discussion
```
User: Review code n√†y v√† th·∫£o lu·∫≠n c√°ch improve:
[code snippet]

Augment s·∫Ω call: discuss(topic="Code review v√† improvement suggestions cho: [code]")
```

## üîß Recommended Models

### Free/Cheap Models (OpenRouter):
- `deepseek/deepseek-r1` - Reasoning model m·ªõi nh·∫•t
- `deepseek/deepseek-chat` - Chat model t·ªët
- `google/gemini-flash-1.5` - Gemini qua OpenRouter
- `meta-llama/llama-3.2-3b-instruct:free` - Free model

### Direct API Models:
- `gemini-1.5-flash` - Gemini tr·ª±c ti·∫øp (n·∫øu c√≥ API key)

## üéØ Workflow trong Augment

1. **User g√µ request** v·ªõi t·ª´ kh√≥a nh∆∞ "th·∫£o lu·∫≠n", "discuss", "so s√°nh"
2. **Augment nh·∫≠n di·ªán** c·∫ßn multi-model discussion
3. **Augment calls** `discuss` tool v·ªõi topic v√† models
4. **MCP server** th·ª±c hi·ªán:
   - L·∫•y perspective t·ª´ Claude (n·∫øu enabled)
   - G·ªçi t·ª´ng model ƒë·ªÉ l·∫•y analysis
   - T·ªïng h·ª£p synthesis
5. **Return k·∫øt qu·∫£** formatted cho user

## üêõ Troubleshooting

### Server kh√¥ng start:
```bash
# Test manually
cd ~/ai-discussion-server/mcp_sdk
OPENROUTER_API_KEY="your-key" python3 mcp_discussion_server.py
```

### Model kh√¥ng available:
- Check model names tr√™n OpenRouter
- Verify API keys
- Try fallback models

### Augment kh√¥ng th·∫•y tools:
- Check config path
- Restart Augment
- Check logs

## üöÄ Advanced Usage

### Custom Model Lists:
```json
{
  "topic": "Best programming language for AI",
  "models": ["deepseek/deepseek-r1", "deepseek/deepseek-chat", "google/gemini-flash-1.5"],
  "include_claude": true
}
```

### Specialized Discussions:
- **Code Review:** Include code snippets in topic
- **Architecture:** Focus on scalability and trade-offs  
- **Technology Choice:** Compare pros/cons
- **Problem Solving:** Multi-angle analysis

## üí° Tips

1. **Be specific** trong topic ƒë·ªÉ c√≥ analysis t·ªët h∆°n
2. **Use 2-3 models** cho balance gi·ªØa quality v√† speed
3. **Include context** trong topic (startup size, requirements, etc.)
4. **Try different model combinations** cho perspectives kh√°c nhau

B√¢y gi·ªù b·∫°n c√≥ th·ªÉ g√µ trong Augment v√† c√≥ cu·ªôc th·∫£o lu·∫≠n multi-AI ngay l·∫≠p t·ª©c! üéâ
